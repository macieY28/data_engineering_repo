{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Initial import & configuration**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install pyarrow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql import SparkSession\n",
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder\\\n",
    "        .appName(\"PysparkCustomerSegmentation\")\\\n",
    "        .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**JSON configuration**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = spark.read.option(\"multiline\",\"true\").json(\"C:/Your/Configuration/Path/config_file.json\")\n",
    "config.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_config = config.withColumn(\"sources\", explode(col(\"sources\"))).select(\"sources.*\")\n",
    "source_config.show()\n",
    "source_config = source_config.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ingest data from csv files with json congifuration**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "\n",
    "    for i in range(len(source_config)):\n",
    "\n",
    "        source = source_config[i]\n",
    "\n",
    "        df_name = f\"df_{source['table_name']}\"\n",
    "\n",
    "        config_schema = source['schema']\n",
    "\n",
    "        schema = StructType([\n",
    "            StructField(field['name'], IntegerType() if field['type'] == \"integer\" else\n",
    "                                              (StringType() if field['type'] == \"string\" else\n",
    "                                              (DateType() if field['type'] == \"date\" else\n",
    "                                              (TimestampType() if field['type'] == \"timestamp\" else\n",
    "                                              (FloatType() if field['type'] == \"float\" else\n",
    "                                              (BooleanType() if field['type'] == \"boolean\" else StringType()))))),\n",
    "            True\n",
    "        )\n",
    "            for field in config_schema['fields']\n",
    "        ])\n",
    "\n",
    "        globals()[df_name] = spark.read.format(\"csv\")\\\n",
    "                                .option(\"header\",\"true\")\\\n",
    "                                .option(\"delimiter\", ';')\\\n",
    "                                .schema(schema)\\\n",
    "                                .csv(source['path'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_data()\n",
    "\n",
    "df_DimCustomer.show()\n",
    "df_SalesOnline.show()\n",
    "df_vSales.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Data tranform & aggregations for customer segmentation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_vSales = df_vSales.drop(col(\"OrderDate\"))\n",
    "df = df_SalesOnline.join(df_vSales, on=\"OrderID\", how=\"left\")\n",
    "df = df.filter(col(\"Customer\") != 'purchase without registration')\n",
    "df = df.groupby(\"CustomerID\").agg(\\\n",
    "                                    round(sum(col(\"SalesAmount\")),2).alias(\"TotalSpends\"),\\\n",
    "                                    sum(col(\"PositionCount\")).alias(\"PurchasedItems\"),\\\n",
    "                                    count(col(\"OrderID\")).alias(\"OrdersCount\"),\\\n",
    "                                    min(col(\"OrderDate\")).alias(\"FirstOrder\"),\\\n",
    "                                    max(col(\"OrderDate\")).alias(\"LastOrder\")\n",
    "                                    )\n",
    "df = df\\\n",
    "        .withColumn(\"AverageBasketSize\", round(df.PurchasedItems/df.OrdersCount,2))\\\n",
    "        .withColumn(\"AverageBasketValue\", round(df.TotalSpends/df.OrdersCount,2))\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_DimCustomer = df_DimCustomer.drop(\"DeliveryAddress\")\n",
    "\n",
    "df_DimCustomer = \\\n",
    "    df_DimCustomer.withColumn(\"City\", substring_index(\"CorrespondenceAddress\",\" \",-1))\\\n",
    "                    .withColumn(\"Age\", round(datediff(current_date(),'BirthDate')/365.25,0))\\\n",
    "                    .withColumn(\"AgeSexSegment\", when((col(\"Gender\")==\"M\") & (col(\"Age\")<26), \"M18\")\\\n",
    "                                                .when((col(\"Gender\")==\"M\") & (col(\"Age\")<35), \"M26\")\\\n",
    "                                                .when((col(\"Gender\")==\"M\") & (col(\"Age\")<50), \"M35\")\\\n",
    "                                                .when((col(\"Gender\")==\"M\") & (col(\"Age\")>50), \"M50\")\\\n",
    "                                                .when((col(\"Gender\")==\"F\") & (col(\"Age\")<26), \"F18\")\\\n",
    "                                                .when((col(\"Gender\")==\"F\") & (col(\"Age\")<35), \"F26\")\\\n",
    "                                                .when((col(\"Gender\")==\"F\") & (col(\"Age\")<50), \"F35\")\\\n",
    "                                                .when((col(\"Gender\")==\"F\") & (col(\"Age\")>50), \"F50\"))\\\n",
    "                    .withColumn(\"FamilySegment\", when((col(\"Gender\")==\"M\") & (col(\"MartialStatus\")==\"married\") & (col(\"Kids\")>0), \"head of the family\")\\\n",
    "                                                .when((col(\"Gender\")==\"M\") & (col(\"MartialStatus\")==\"married\") & (col(\"Kids\")==0), \"husband\")\\\n",
    "                                                .when((col(\"Gender\")==\"M\") & (col(\"MartialStatus\")!=\"married\") & (col(\"Kids\")>0),\"father\")\\\n",
    "                                                .when((col(\"Gender\")==\"M\") & (col(\"MartialStatus\")!=\"married\"),\"single\")\\\n",
    "                                                .when((col(\"Gender\")==\"F\") & (col(\"MartialStatus\")==\"married\") & (col(\"Kids\")>0),\"mother&wife\")\\\n",
    "                                                .when((col(\"Gender\")==\"F\") & (col(\"MartialStatus\")==\"married\") & (col(\"Kids\")==0),\"wife\")\\\n",
    "                                                .when((col(\"Gender\")==\"F\") & (col(\"MartialStatus\")!=\"married\") & (col(\"Kids\")>0),\"single mother\")\\\n",
    "                                                .when((col(\"Gender\")==\"F\") & (col(\"MartialStatus\")!=\"married\"), \"single\"))\\\n",
    "                    .withColumn(\"DemographicSegment\",when(col(\"City\").isin([\"Warszawa\", \"Kraków\", \"Poznań\", \"Wrocław\", \"Łódź\", \"Gdańsk\"]), \"big city\")\\\n",
    "                                                .when(col(\"City\").isin([\"Katowice\", \"Szczecin\", \"Bydgoszcz\", \"Częstochowa\", \"Lublin\", \"Białystok\"]), \"city\")\\\n",
    "                                                .otherwise(\"small town/village\"))\n",
    "\n",
    "df = df_DimCustomer.join(df, on=\"CustomerID\", how=\"inner\")\n",
    "\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Save results to parquet file**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pandas_df = df.toPandas()\n",
    "table = pa.Table.from_pandas(pandas_df)\n",
    "pq.write_table(table, \"C:/Your/Result/Path/customer_segmentation.parquet\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
